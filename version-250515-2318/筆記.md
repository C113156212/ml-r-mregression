太好了，我來**一步步列出完整的公式與代入數值計算過程**，你會清楚看到從輸入 → 預測 → 誤差 → 梯度 → 權重更新的完整流程。

---

## 🧮 訓練資料：

```plaintext
X = [[30, 1],    ← score, performance
     [70, 3]]

y = [1, 0]       ← 實際值（admitted 與否）
```

---

## 1️⃣ 初始權重與截距：

```plaintext
w = [0.1, 0.1]   ← 初始權重
b = 0.0          ← 初始截距
```

---

## 2️⃣ 預測值 (Sigmoid 計算)：

公式：

$$
z = X \cdot w + b
$$

逐筆計算：

* 第 1 筆：

  $$
  z = 30 \times 0.1 + 1 \times 0.1 + 0 = 3.0 + 0.1 = 3.1
  $$

* 第 2 筆：

  $$
  z = 70 \times 0.1 + 3 \times 0.1 + 0 = 7.0 + 0.3 = 7.3
  $$

然後套入 sigmoid：

$$
\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}
$$

* 第 1 筆：

  $$
  \hat{y}_1 = \frac{1}{1 + e^{-3.1}} \approx 0.956
  $$

* 第 2 筆：

  $$
  \hat{y}_2 = \frac{1}{1 + e^{-7.3}} \approx 0.9993
  $$

所以：

```plaintext
y_hat ≈ [0.956, 0.9993]
```

---

## 3️⃣ 計算誤差：

$$
\text{error} = \hat{y} - y = [0.956 - 1, 0.9993 - 0] = [-0.044, 0.9993]
$$

---

## 4️⃣ 梯度（偏導數）

### 權重梯度：

$$
\frac{\partial L}{\partial w} = \frac{1}{n} \cdot X^T \cdot \text{error}
$$

先計算：

```plaintext
X^T = [[30, 70],
       [1, 3]]

error = [-0.044, 0.9993]
```

矩陣乘法：

```plaintext
dw[0] = (30 * -0.044 + 70 * 0.9993) / 2 ≈ 34.33
dw[1] = (1 * -0.044 + 3 * 0.9993) / 2 ≈ 1.48
```

所以：

```plaintext
dw ≈ [34.33, 1.48]
```

### 截距梯度：

$$
\frac{\partial L}{\partial b} = \frac{1}{n} \cdot \sum \text{error} = (-0.044 + 0.9993)/2 ≈ 0.478
$$

---

## 5️⃣ 更新權重與截距：

使用學習率 $\eta = 0.01$

$$
w_{\text{new}} = w - \eta \cdot \frac{\partial L}{\partial w}
$$

$$
= [0.1, 0.1] - 0.01 \cdot [34.33, 1.48] = [-0.2433, 0.0852]
$$

$$
b_{\text{new}} = 0.0 - 0.01 \cdot 0.478 = -0.0048
$$

---

## ✅ 結論：

| 欄位    | 初始值 | 梯度    | 更新後     |
| ----- | --- | ----- | ------- |
| $w_0$ | 0.1 | 34.33 | -0.2433 |
| $w_1$ | 0.1 | 1.48  | 0.0852  |
| $b$   | 0.0 | 0.478 | -0.0048 |

---

這就是一次完整的 **邏輯回歸的梯度下降更新循環**。

要不要我們繼續跑好幾輪（epoch）來觀察損失值是否收斂？或是你想手動嘗試一次計算看看？
